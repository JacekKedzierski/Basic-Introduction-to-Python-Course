{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-K3jSVqXVABh"
   },
   "source": [
    "# AI in Medicine\n",
    "\n",
    "### Python Programming: *computer vision*, MRI and *deep learning*\n",
    "\n",
    "* **Instructor**: Marc-Andre Schulz, AG Ritter, Charité (marc-andre.schulz@charite.de). \n",
    "* **Target audience**: Medical students from Charité\n",
    "* **Course date**: January 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Hx47INFVABl"
   },
   "source": [
    "## Aims of this session\n",
    "\n",
    "- How to work with images and MRI data in programming languages. \n",
    "- How to use a convolutional neural network (CNN) with images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRiIw-KBVABl"
   },
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAmrnMtuVABm"
   },
   "source": [
    "Code cells contain the *#TODO* mark which you need to replace and fill with the appropriate code.\n",
    "Solutions can be found at the end of the Notebook, only go there if you are really stuck. Ask questions first!\n",
    "The exercises are sequential, i.e. you need to often finish them in the right order. Sometimes solutions for previous exercises can be found in later excersises but that would be boring. You will be able to take away most from this lecture if you actually try to solve all excercises.\n",
    "\n",
    "**Feel free to ask questions anytime! ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUN4img9VABn"
   },
   "source": [
    "# 1. Working with normal images\n",
    "### Opening images with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDRGRBT-VABo"
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfOhTtnpVABp"
   },
   "source": [
    "We have an image file stored in our directory which we would like to work with using Python. First, we have to open the image using a file reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-TRXQ9H0VABp"
   },
   "outputs": [],
   "source": [
    "!mkdir -p data; wget -q -P data https://raw.githubusercontent.com/volkamerlab/ai_in_medicine/base-2021-07/data/car.jpg\n",
    "image_path = \"data/car.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hy2H1GvKVABq"
   },
   "source": [
    "There are many different tools to read a jpeg image into python. Here we will use the common Pillow (PIL) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6nn82fYVABr"
   },
   "outputs": [],
   "source": [
    "# loading the image\n",
    "image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsXHZfsNVABr"
   },
   "source": [
    "**Exercise 1.1: Show the image using matplotlib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHF90o2zVABs"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Buj8SksVABt"
   },
   "source": [
    "### Images on computers\n",
    "Computers store everything in binary code, only 1s and 0s. However, on a higher level, an operating system (OS) stores data in a more structured fashion. This allows us to understand and modify the data much better than the binary information. How are images stored and handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UVQDdYDVABt"
   },
   "source": [
    "The result from exercise 1.1 shows the image in a 2D grid, i.e. it has an X and a Y axis. A 2D grid can be seen as a simple matrix. In python we often store any kind of matrix, such as a vector, a matrix or a tensor as an array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qtx4vvMmVABt"
   },
   "source": [
    "**Exercise 1.2: Use numpy to convert the image into an array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9A9_ErkVABu",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "image_array = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBW6tKjQVABu"
   },
   "source": [
    "**Exercise 1.3: Print the shape of the array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1KJAZbCVABu",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Si_sDEckVABu"
   },
   "source": [
    "You'll notice that the matrix is in fact 3D, not 2D! The last dimension represents the color dimension, it has 3 channels: red, green and blue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjHN8QWsVABw"
   },
   "source": [
    "### What's inside the array?\n",
    "If the image is simply a matrix, we should be able to have a look at what's inside!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dh3MeiboVABw"
   },
   "source": [
    "**Exercise 1.4: Use the print function to print the contents of image_array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThMbNrE-VABx",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSc97zj4VABx"
   },
   "source": [
    "The dots in the output show that the output is too long to be printed in this window. For simplicity, let's just look at the first 5x5 values using slicing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sN6XadIoVABx"
   },
   "source": [
    "**Exercise 1.5: Use the print function to print the contents of the first 5x5 items in image_array**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiRodG26VABy"
   },
   "source": [
    "Hint: Use brackets \"[]\" for selecting, \",\" to separate slicing per dimension and use \":X\" to select from the beginning to value X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suPQvoCGVABy",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw9YhiSSVABy"
   },
   "source": [
    "You should see 5 rows, nested within 5 larger rows. Each row contains three values: red, green and blue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9izJ4WdVABy"
   },
   "source": [
    "# 2. Modifying image contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyFFgcMzVABy"
   },
   "source": [
    "Next, let's see how we can modify the contents of the matrix and how that effects plotting of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnE6r27EVABz"
   },
   "source": [
    "**Exercise 2.1: Set the first 100x100 values to zero and then plot the image. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgeP9hwTVABz",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "zeroed_image = np.copy(image_array) # copy the values to a new variable\n",
    "zeroed_image[] # TODO select the desired region and set that value to 0\n",
    "\n",
    "plt.imshow(zeroed_image) # plot the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rx1BGWFKVABz"
   },
   "source": [
    "Notice how the top left corner is simply black now? If we set all three RGB channels to zero, the pixels will be black."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5_4LwWjVAB0"
   },
   "source": [
    "**Exercise 2.2: Color the first 100x100 values white this time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qu8ZdoPuVAB0"
   },
   "source": [
    "First we need to find out which range the image values lie in, typically colors are encoded between 0-1 (as floats) or 0-255 (as integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pF8uvTLVAB0",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# use the print and the np.max() function to find out the pixel value which represents white\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayXkT3T9VAB0",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# now we do the same as in Exercise 2.1 but set the values to the max value from above instead of 0.\n",
    "# TODO\n",
    "\n",
    "plt.imshow(zeroed_image) # plot the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_Yi8H_8VAB1"
   },
   "source": [
    "**Exercise 2.3: Remove red from the image.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42yuGSDXVAB1"
   },
   "source": [
    "Set all pixels in the red color channel to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItaYXBwtVAB1"
   },
   "source": [
    "Hint: use *:* on the two spatial dimensions and *0* on the channel dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGLZufghVAB1",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "no_red_image = np.copy(image_array)\n",
    "no_red_image[# TODO\n",
    "plt.imshow(no_red_image) # plot the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8jxBBCLY8m8"
   },
   "source": [
    "**Exercise 2.4: Show only the red channel**\n",
    "\n",
    "Now you need to set all the other channels to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79SsTVpXY6sK"
   },
   "outputs": [],
   "source": [
    "red_only_image = np.copy(image_array)\n",
    "# the easy solution is using 2 lines, but can you also do it in 1 line?\n",
    "red_only_image[# TODO\n",
    "\n",
    "# plot the image\n",
    "plt.imshow(red_only_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5WfVQQmVAB1"
   },
   "source": [
    "**Exercise 2.5: Reduce the color intensity by dividing the entire matrix by 4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBxNHL-qVAB2",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reduced_image = np.copy(image_array)\n",
    "reduced_image = # TODO\n",
    "plt.imshow(reduced_image.astype(\"uint8\")) # plot the image, note that we need to convert it back to integers first!\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Jad9QtLVAB2"
   },
   "source": [
    "Next, we will apply a simple **filter/kernel** to the image, which is typical to what a convolutional neural network does. We will convolve the filter with the image, meaning that the filter (which is smaller than the image) will be moved across all the spatial positions in the image. This process is often called sliding window as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8ASCyMZVAB2",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhxmcYqTVAB2",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# first we create two different kinds of kernel.\n",
    "horizontal_kernel = np.array([\n",
    "    [1, 1, 1],\n",
    "    [0, 0, 0],\n",
    "    [-1, -1,-1]\n",
    "])\n",
    "\n",
    "vertical_kernel = np.array([\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0,1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mylB5aBjVAB3"
   },
   "source": [
    "The two kernels above are typical edge detector filters, edge detection is important to find boundaries between different objects. By just looking at the numbers and considering how the kernels are slid over the image, one can understand that the horizontal kernel works alongs the y-axis, highlighting patterns where there is a sharp difference in values above and below the line. The same reasoning can be used to make sense of the vertical kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cyMleOPVAB3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "horizontally_filtered = convolve(image_array[:,:,0], horizontal_kernel)\n",
    "plt.imshow(horizontally_filtered, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wS5St5u5VAB4",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "vertically_filtered = convolve(image_array[:,:,0], vertical_kernel)\n",
    "plt.imshow(vertically_filtered, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3m5R9z3VAB4"
   },
   "source": [
    "As you can see the filters highlight all the horizontal and vertical edges in the image, however since the image contains many \"grainy\" areas like the road and the buildings, as well as diagonal lines, such as the road markings it is quite difficult to make sense of the image content from these results. Nevertheless, the car, as the main object, is highlighted nicely in both versions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sX_Qy9UVAB4"
   },
   "source": [
    "# 3. MRI are matrices as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koJmMBl2VAB4"
   },
   "source": [
    "**Exercise 3.1: Load the MR image.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuXm-sexVAB4"
   },
   "source": [
    "Check where the MRI file is located and its filename to load it into a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrTtoLpxVAB5",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# download the files\n",
    "!wget -q -P data https://raw.githubusercontent.com/volkamerlab/ai_in_medicine/base-2021-07/data/MRI_subject.nii.gz\n",
    "\n",
    "# first we load the image using the nibabel (nib) library\n",
    "nifti = nib.load(#TODO)\n",
    "# we can find meta information in the header of the object\n",
    "print(nifti.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0qdj0pMVAB5",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# in order to access the data we can use the object's get_data() function\n",
    "mri_data = nifti.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBy0QzA3VAB5"
   },
   "source": [
    "**Exercise 3.2: Print the shape of the MRI and it's content.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7yOIL1wVAB5",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# print the shape\n",
    "# TODO\n",
    "# print the content\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQhvNsFYVAB5"
   },
   "source": [
    "**Exercise 3.3: Plot a slice of the matrix using pyplot.**\n",
    "Before you have used pyplot to plot the image of the car. In order to plot the 3D MRI as a 2D image we need to select a single slice only.\n",
    "\n",
    "Hint: it makes sense to select a slice in the center as the slices on the very edge of the MRI are typically empty.\n",
    "\n",
    "Hint: you need to use array indexing. For 2 dimensions you should use the all selector `:` and for the other dimension you need to select a slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hF1gnpvyVAB6",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO plot the MRI and try the same code with selecting different \n",
    "# axis to show the axial, coronal and sagittal views of the MRI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSa9u512VAB6"
   },
   "source": [
    "Don't like the color stain? You can set another parameter in the `imshow` function called to paint the image in grayscale: `cmap='gray'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOCeGosMVAB6",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO plot the image in gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPAz7HU2VAB6"
   },
   "source": [
    "# 4. Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04ch7SlyVAB7"
   },
   "source": [
    "As you have learned in the lecture, convolutional neural networks apply **filters** in a hierarchical (layer-wise) fashion. Using reasoning to come up with simple edge detector filters, like above, or even face recognition filters (see [Viola Jones algorithm](https://de.wikipedia.org/wiki/Viola-Jones-Methode)) seems plausible, but doing that for abstract concepts such as cars, or brain diseases is impossible. Convolutional neural networks are able to learn those filters automatically using backpropagation. Interestingly, it was investigated, that CNNs trained on images often learn exactly those kind of edge detection filters in their earliest layers. Since different filters are combined along the depth of the network, more challenging concepts can be extracted by using deep networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5p35PyBVAB7"
   },
   "source": [
    "Next, we will use a trained neural network to predict on the MR image from above whether the subject has Alzheimer's disease or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWewZKmfVAB7"
   },
   "source": [
    "**Exercise 4.1: Mask the image. **\n",
    "\n",
    "Currently, the image still contains the brain skull. We can use a brain mask as a simple way to remove it. Our brain mask is **binary** meaning that it only contains 1s and 0s. A 1 everywhere there is gray matter or white matter, and a 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjmGq3eCVAB7"
   },
   "outputs": [],
   "source": [
    "!wget -q -P data https://raw.githubusercontent.com/volkamerlab/ai_in_medicine/base-2021-07/data/binary_brain_mask.nii.gz\n",
    "mask = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRAUP_KNVAB7",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(mask.shape)\n",
    "plt.imshow(mask[:,:,70], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tapGaSY5VAB8",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# apply the mask to the image\n",
    "masked_mri = # TODO\n",
    "# plot the masked image\n",
    "plt.imshow(#TODO)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEPdWvc3VAB8"
   },
   "source": [
    "**Exercise 4.2: Adjust the image size. **\n",
    "\n",
    "The network expects inputs to be of size (96, 114, 96) which is exactly **half** of the size of the MRI. We can use the `zoom` function from `scipy` to match the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmCNF5bJVAB8",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fagmjp2LVAB8",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mri_data_zoomed = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_wLgdPxVAB9",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(mri_data_zoomed.shape)\n",
    "plt.imshow(mri_data_zoomed[:,:,48], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChIpK-wVVAB9"
   },
   "source": [
    "Note: you might notice that the masking together with the zooming isn't perfect. Better methods to strip the skull from individual subjects exist such as FSL BET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6wi_ntnVAB9"
   },
   "source": [
    "## Network definition\n",
    "Below the class 'NeuralNetwork' specifies the class for our CNN, defined in the PyTorch framework. You do not need to understand all of it for now, but you can identify the different building blocks. You can see Convolutional, MaxPooling and Linear (fully connected) layers, as well as dropout, ELU and sigmoid activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAlOk6KbVAB9",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBUYlY4cVAB9",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Convert the zoomed and masked MRI to a PyTorch Tensor.\n",
    "# Details for the curious:\n",
    "# This is simply another class to handle a multi-dimensional matrix.\n",
    "# The neural network expects the shape of the data to be 5 dimensional,\n",
    "# so we add 2 length 1-dimensions at the beginning (unsqueeze).\n",
    "# Also we convert the values to float.\n",
    "mri_tensor = torch.from_numpy(mri_data_zoomed).unsqueeze(0).unsqueeze(0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5p7EQIdVAB-",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, drp_rate=0.3):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.drp_rate = drp_rate\n",
    "        self.dropout = nn.Dropout3d(p=self.drp_rate)\n",
    "        self.Conv_1 = nn.Conv3d(1, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool_1 = nn.MaxPool3d(kernel_size=3, stride=3, padding=0)\n",
    "        self.Conv_2 = nn.Conv3d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool_2 = nn.MaxPool3d(kernel_size=3, stride=2, padding=0)\n",
    "        self.Conv_3 = nn.Conv3d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.Conv_4 = nn.Conv3d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.Conv_5 = nn.Conv3d(64, 36, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool_4 = nn.MaxPool3d(kernel_size=4, stride=2, padding=0)\n",
    "        \n",
    "        self.classifier_scratch = nn.Sequential(\n",
    "            nn.Linear(1296, 80),\n",
    "            nn.Linear(80, 1)\n",
    "        )\n",
    "\n",
    "    def encode(self, x, print_size=False):\n",
    "        if print_size:\n",
    "            print(x.shape)\n",
    "        x = F.elu(self.Conv_1(x))\n",
    "        h = self.dropout(self.pool_1(x))\n",
    "        x = F.elu(self.Conv_2(h))\n",
    "        if print_size:\n",
    "            print(x.shape)\n",
    "        h = self.dropout(self.pool_2(x))\n",
    "        x = F.elu(self.Conv_3(h))\n",
    "        if print_size:\n",
    "            print(x.shape)\n",
    "        x = F.elu(self.Conv_4(x))\n",
    "        if print_size:\n",
    "            print(x.shape)\n",
    "        x = F.elu(self.Conv_5(x))\n",
    "        if print_size:\n",
    "            print(x.shape)\n",
    "        h = self.dropout(self.pool_4(x))\n",
    "        if print_size:\n",
    "            print(h.shape)\n",
    "        \n",
    "        return h\n",
    "\n",
    "    def forward(self, x):\n",
    "        print_size = False\n",
    "        x = self.encode(x, print_size=print_size)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier_scratch(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def flatten(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfmC2UjeVAB-",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create an instance of the NeuralNetwork class\n",
    "net = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sASDgva8VAB-"
   },
   "outputs": [],
   "source": [
    "# using the print function we can see the parts of the model\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMXW77svVAB_"
   },
   "source": [
    "Load the pre-trained weights of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAMj9msQgvsO"
   },
   "outputs": [],
   "source": [
    "!wget -q -P data https://raw.githubusercontent.com/volkamerlab/ai_in_medicine/base-2021-07/data/cnn_params.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AU7yMfXfVAB_"
   },
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(\"data/cnn_params.h5\", map_location='cpu'), strict=False)\n",
    "# we need to set the model to 'evaluation' mode to turn off dropout during prediction\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EP0SX1WlVAB_"
   },
   "source": [
    "The neural network was trained to decode Alzheimer's Disease from healthy controls. Hence, it is a **binary classification**. That is why the 'sigmoid' activation is used as an output: it squishes the values between 0 and 1 making them look like an S-curve:\n",
    "\n",
    "![Sigmoid Curve Image](https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Sigmoid-function-2.svg/1920px-Sigmoid-function-2.svg.png)\n",
    "\n",
    "We have trained the network using the class encodings:\n",
    "\n",
    "0 - Healthy Control\n",
    "\n",
    "1 - Alzheimer's Disease Patient\n",
    "\n",
    "So any value that the network outputs that is above 0.5 are classified as AD, whereas the values below 0.5 are classified as HC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN8Z7McBVAB_"
   },
   "source": [
    "**Exercise 4.3: Use the network to predict on the MR image. **\n",
    "\n",
    "Now we have ensured that the image has the right dimension and data type, the network has is ready with some pre-trained weights. As a last exercise you should use the 'forward' function of the neural network to predict which class the image belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbbO15rBVACA",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "result = # TODO\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgDNn3ycVACA"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qINNQocHVACA"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_U1ZOZNVACB"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCwmDoswVACB"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqgIAiYJVACB"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXazrNGzVACC"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlRCE2JGVACC"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11VhyF3RVACC"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_txN8vkMVACC"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJYyfaAIVACD"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqLHvXIhVACD"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRpo6DEHVACD"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7wVSmLCVACE"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPQwHRzoVACF"
   },
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't go past here if you want to solve the questions on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yn78YYNiVACG"
   },
   "source": [
    "**Exercise 1.1: Show the image using matplotlib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_OwWUXCVACG"
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsnbu00lVACG"
   },
   "source": [
    "**Exercise 1.2: Use numpy to convert the image into a matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDxC52ILVACG",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "image_array = np.array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8hlnAyYVACG"
   },
   "source": [
    "**Exercise 1.3: Print the shape of the matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zHaTpwlVACG"
   },
   "outputs": [],
   "source": [
    "print(image_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKO29toKVACH"
   },
   "source": [
    "**Exercise 1.4: Plot only one of the color channels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ss0MvlXYVACH"
   },
   "outputs": [],
   "source": [
    "# select all from the first two dimensions and only a single value from the last dimension\n",
    "image_array_single_color = image_array[:,:,0]\n",
    "# plot the image\n",
    "plt.imshow(image_array_single_color, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mr_8bkb8VACH"
   },
   "source": [
    "**Exercise 1.4: Use the print function to print the contents of image_array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hB9jDEBwVACH"
   },
   "outputs": [],
   "source": [
    "print(image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kc_B6wNnVACH"
   },
   "source": [
    "Exercise 1.5: Use the print function to print the contents of the first 5x5 items in image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSPO2J5vVACH"
   },
   "outputs": [],
   "source": [
    "print(image_array[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wO9DJa3oVACI"
   },
   "source": [
    "**Exercise 2.1: Set the first 100x100 values to zero and then plot the image. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UPdUMNhVACI"
   },
   "outputs": [],
   "source": [
    "zeroed_image = np.copy(image_array) # copy the values to a new variable\n",
    "zeroed_image[:100,:100] = 0\n",
    "\n",
    "plt.imshow(zeroed_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpZQga15VACI"
   },
   "source": [
    "**Exercise 2.2: Color the first 100x100 values white this time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfVqX06_VACI"
   },
   "source": [
    "First we need to find out which range the image values lie in, typically colors are encoded between 0-1 (as floats) or 0-255 (as integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sk5G5eUJVACI"
   },
   "outputs": [],
   "source": [
    "# use the print and the np.max() function to find out the pixel value which represents white\n",
    "print(np.max(zeroed_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5HHeIuNVACJ"
   },
   "outputs": [],
   "source": [
    "# now we do the same as in Exercise 2.1 but set the values to the max value from above instead of 0.\n",
    "zeroed_image[:100, :100] = 255\n",
    "\n",
    "plt.imshow(zeroed_image) # plot the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxKjXj6CVACJ"
   },
   "source": [
    "**Exercise 2.3: Remove red from the image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSwjBI5MVACJ"
   },
   "outputs": [],
   "source": [
    "no_red_image = np.copy(image_array)\n",
    "no_red_image[:,:,0] = 0\n",
    "plt.imshow(no_red_image) # plot the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuyqWnn4ZLNc"
   },
   "source": [
    "**Exercise 2.4: Show only the red channel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99bkzpZpZOqA"
   },
   "outputs": [],
   "source": [
    "red_only_image = np.copy(image_array)\n",
    "red_only_image[:,:,1:] = 0 # channels 1 and 2 will be set to zero\n",
    "plt.imshow(red_only_image) # plot the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW4_x3uFVACJ"
   },
   "source": [
    "**Exercise 2.5: Reduce the color intensity by dividing the entire matrix by 4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abCzZcSvVACJ"
   },
   "outputs": [],
   "source": [
    "reduced_image = np.copy(image_array)\n",
    "reduced_image = reduced_image / 4\n",
    "plt.imshow(reduced_image.astype(\"uint8\")) # plot the image, note that we need to convert it back to integers first!\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwOmTfNUVACK"
   },
   "source": [
    "**Exercise 3.1: Load the MR image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcDrq6KoVACK"
   },
   "outputs": [],
   "source": [
    "!wget -q -P data https://raw.githubusercontent.com/volkamerlab/ai_in_medicine/base-2021-07/data/MRI_subject.nii.gz\n",
    "!wget -q -P data https://raw.githubusercontent.com/volkamerlab/ai_in_medicine/base-2021-07/data/binary_brain_mask.nii.gz\n",
    "\n",
    "# first we load the image using the nibabel (nib) library\n",
    "nifti = nib.load(\"data/MRI_subject.nii.gz\")\n",
    "# we can find meta information in the header of the object\n",
    "print(nifti.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mL_OcJcxVACK",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# in order to access the data we can use the object's get_data() function\n",
    "mri_data = nifti.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ce3FnZbVACL"
   },
   "source": [
    "**Exercise 3.2: Print the shape of the MRI and it's content.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYJw8ua4VACL"
   },
   "outputs": [],
   "source": [
    "# print the shape\n",
    "print(mri_data.shape)\n",
    "# print the content\n",
    "print(mri_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-63RCjuFVACL"
   },
   "source": [
    "**Exercise 3.3: Plot a slice of the matrix using pyplot.**\n",
    "Before you have used pyplot to plot the image of the car. In order to plot the 3D MRI as a 2D image we need to select a single slice only.\n",
    "\n",
    "Hint: it makes sense to select a slice in the center as the slices on the very edge of the MRI are typically empty.\n",
    "\n",
    "Hint: you need to use array indexing. For 2 dimensions you should use the all selector `:` and for the other dimension you need to select a slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_X6SjUqVACL"
   },
   "outputs": [],
   "source": [
    "plt.imshow(mri_data[:,:,90])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QroeG4q6VACM"
   },
   "source": [
    "Don't like the color stain? You can set another parameter in the `imshow` function called to paint the image in grayscale: `cmap='gray'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCNt2peaVACM"
   },
   "outputs": [],
   "source": [
    "plt.imshow(mri_data[:,:,90], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cF2RCDzVACN"
   },
   "source": [
    "**Exercise 4.1: Mask the image. **\n",
    "\n",
    "Currently, the image still contains the brain skull. We can use a brain mask as a simple way to remove it. Our brain mask is **binary** meaning that it only contains 1s and 0s. A 1 everywhere there is gray matter or white matter, and a 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Od0zIKOugF1s"
   },
   "outputs": [],
   "source": [
    "!wget -q -P data https://raw.githubusercontent.com/volkamerlab/ai_in_medicine/base-2021-07/data/binary_brain_mask.nii.gz\n",
    "mask = nib.load(\"data/binary_brain_mask.nii.gz\").get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5PqMOp5VACN"
   },
   "outputs": [],
   "source": [
    "# apply the mask to the image\n",
    "masked_mri = mri_data * mask\n",
    "# plot the masked image\n",
    "plt.imshow(masked_mri[:,:,90], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kqn-q2tQVACN"
   },
   "source": [
    "**Exercise 4.2: Adjust the image size. **\n",
    "\n",
    "The network expects inputs to be of size (96, 114, 96) which is exactly **half** of the size of the MRI. We can use the `zoom` function from `scipy` to match the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiDbs7n_VACN",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9K3AFmXSVACN",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mri_data_zoomed = zoom(input=masked_mri, zoom=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hn3VjxEpVACN"
   },
   "source": [
    "**Exercise 4.3: Use the network to predict on the MR image. **\n",
    "\n",
    "Now we have ensured that the image has the right dimension and data type, the network has is ready with some pre-trained weights. As a last exercise you should use the 'forward' function of the neural network to predict which class the image belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VA0Rkg4-VACO",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "result = net.forward(mri_tensor)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBrK7FQ4VACO"
   },
   "source": [
    "The image should be classified as Alzheimer's Disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5bsgSP5VACO",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vUN4img9VABn",
    "8Buj8SksVABt",
    "XjHN8QWsVABw",
    "d9izJ4WdVABy",
    "4sX_Qy9UVAB4",
    "RPAz7HU2VAB6",
    "HgDNn3ycVACA",
    "qINNQocHVACA",
    "X_U1ZOZNVACB",
    "kCwmDoswVACB",
    "nqgIAiYJVACB",
    "JXazrNGzVACC",
    "dlRCE2JGVACC",
    "11VhyF3RVACC",
    "_txN8vkMVACC",
    "xJYyfaAIVACD",
    "iqLHvXIhVACD",
    "LRpo6DEHVACD",
    "Y7wVSmLCVACE",
    "nPQwHRzoVACF"
   ],
   "name": "Copy of week2_session2_images-MRI-dl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
